import nltk
import nltk.classify.util
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.classify import NaiveBayesClassifier
import glob
import re
import random
from nltk.stem import WordNetLemmatizer
wl = wordnet_lemmatizer = WordNetLemmatizer()



def md(words):
    wrds = [word for word in words if word not in stopwords.words("english")]
    alpa = [word for word in wrds if word.isalpha() == True]
    goodwrds = [word for word in alpa if len(word) != 1 ]
    usefulwrds = [wl.lemmatize(word) for word in goodwrds]
    dictionary = dict((word,True) for word in usefulwrds)
    return dictionary
    
ham_list =[]
file = glob.glob('ham/*')
for mail in file:
    with open(mail) as m:
        words= word_tokenize(m.read().lower())
        ham_list.append((md(words), "ham"))



spam_list =[]
emails = glob.glob('spam/*')
for mails in emails:
    with open(mails) as t:
        um = word_tokenize(re.split(r'[Ss][Uu][Bb][Jj][Ee][Cc][Tt]',t.read().lower(),re.M)[1])
        spam_list.append((md(um), "spam")) 
        
        
combined_list = ham_list + spam_list
random.shuffle(combined_list)

training_part = int(len(combined_list) * .7)

training_set = combined_list[:training_part]
test_set =  combined_list[training_part:]

classifier = NaiveBayesClassifier.train(training_set)
accuracy = nltk.classify.util.accuracy(classifier, test_set)
print("Accuracy is: ", accuracy * 100)




